# ***NOTE on PRUNE***
#  PA seems to add fields in pacthes and some fields do not apply to most environements
#  So the prune command eliminates all undefined fields and unneeded to store only what your envionment uses
#  If you want more fields than being stored, add them to the whitelist in the prune statement
#  This also eliminates the columnX in the created document

filter {
    if "PAN-OS_syslog" in [tags] {
        # ADDED USER ID
        if ([message] =~ /USERID/) {
            csv {
                    source  => "message"
                    columns => ["FUTURE_USER_", "Receive_Time", "Serial_Number", "Type", "Threat_or_Content_Type",
                                "FUTURE_USE_", "Generated_Time", "Virtual_System", "Source_IP", "User",
                                "Data_Source_Name", "Event_ID", "Repeat_Count", "Time_Out_Threshold",
                                "Source_Port", "Destination_Port", "Data_Source", "Data_Source_Type",
                                "Sequence_Number_", "Action_Flags", "Device_Group_Hierarchy_Level_1",
                                "Device_Group_Hierarchy_Level_2", "Device_Group_Hierarchy_Level_3",
                                "Device_Group_Hierarchy_Level_4", "Virtual_System_Name_", "Device_Name",
                                "Virtual_System_ID", "Factor_Type_", "Factor_Completion_Time", "Factor_Number",
                                "FUTURE_USE", "FUTURE_USE", "User_Group_Flags", "User_by_Source",
                                "High_Resolution_Timestamp"]
            }

            prune { interpolate     => true
                    blacklist_names => ["FUTURE_USER_", "FUTURE_USE_", "Sequence_Number_", "Virtual_System_Name_", "Factor_Type_", "FUTURE_USE", "FUTURE_USE", "User_by_Source"]
                }

            mutate { convert     => [ "Sequence_Number", "integer" ]
                    add_tag      => [ "PAN-OS_USERID"]
                    # REMOVE DUPLICATE LOGS
                    remove_field => [ "event" ]
                    remove_field => [ "message" ]       
                    remove_tag   => ["PAN-OS_syslog"]
                }

            date {
                    match => [ "timestamp", "dd/MM/yyyy HH:mm:ss" ]
                    target => "@timestamp"
                }

            # Resolve IP address to names.  The DNS filter can be a performance issue is receing over 400 requstes per second.
            # Do not use Logstash DNS Filter Cache parameters, it forces a single thread process regaurdless of how many workers you have
            # For best performance, install dnsmasq on the logstash server
            # Make sure your dnsmasq points to an internal DNS to resolve local RFC1918 addresses
            if [Source_IP] {
                mutate {
                    add_field => { "source_ip_resolved" => "%{Source_IP}" }
                    
                }   
                dns {
                    reverse        => [ "source_ip_resolved"] 
                    action         => "replace"
                    hit_cache_size => 4096
                    # Your own private DNS SERVERS should go here
                    nameserver     => [ "10.121.11.5", "10.121.11.8" ]
                    timeout        => 1
                }     
            }
        }
    }
}